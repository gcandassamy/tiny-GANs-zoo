{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import Critic, Generator, initialize_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters setting (following the recommendation in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-5  \n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "IMG_CHANNELS = 1\n",
    "Z_DIM = 128\n",
    "NUM_EPOCHS = 5\n",
    "CRIT_FEAT = 64\n",
    "GEN_FEAT = 64\n",
    "NUM_CRITIC_ITERS = 5\n",
    "WEIGHT_CLIP = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reproducibility..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_SEED = 42\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "random.seed(MANUAL_SEED)\n",
    "torch.use_deterministic_algorithms(mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( (0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Critic and the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(Z_DIM, IMG_CHANNELS, GEN_FEAT).to(dev)\n",
    "G.apply(initialize_weights)\n",
    "C = Critic(IMG_CHANNELS, CRIT_FEAT).to(dev)\n",
    "C.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_G = optim.RMSprop(G.parameters(), lr=LEARNING_RATE)\n",
    "opt_C = optim.RMSprop(C.parameters(), lr=LEARNING_RATE)\n",
    "fixed_z = torch.randn(32, Z_DIM, 1, 1).to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_data = SummaryWriter(f\"logs/MNIST\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Wasserstein GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.train()\n",
    "C.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_id, (data, _) in enumerate(tqdm(dataloader)):\n",
    "        data = data.to(dev)\n",
    "        curr_bs = data.shape[0]\n",
    "\n",
    "        # Train the Critic for specified number of iterations\n",
    "        # Objective: max E[C(real)] - E[C(fake)]\n",
    "        for _ in range(NUM_CRITIC_ITERS):\n",
    "            C.zero_grad()\n",
    "            z = torch.randn(curr_bs, Z_DIM, 1, 1).to(dev)\n",
    "            fake = G(z)\n",
    "            C_real = C(data).reshape(-1)\n",
    "            C_fake = C(fake.detach()).reshape(-1)\n",
    "            loss_C = - (torch.mean(C_real) - torch.mean(C_fake)) \n",
    "            loss_C.backward()\n",
    "            opt_C.step()\n",
    "\n",
    "            # Enforcing Lipschitz constraint by weight clipping\n",
    "            for param in C.parameters():\n",
    "                param.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "        \n",
    "        # Train the Generator\n",
    "        # Objective: max E[C(fake)] <--> min - E[C(fake)]\n",
    "        G.zero_grad()\n",
    "        G_fake = C(fake).reshape(-1)\n",
    "        loss_G = - torch.mean(G_fake)\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        # Printing losses and logging to TensorBoard...\n",
    "        if batch_id % 100 == 0 and batch_id > 0:\n",
    "            # Enter evaluation mode\n",
    "            G.eval()\n",
    "            C.eval()\n",
    "            print(f\"Epoch [{epoch+1} / {NUM_EPOCHS}] Batch [{batch_id}/ {len(dataloader)}] Loss C: {loss_C.item():.4f} Loss G: {loss_G.item():.4f}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = G(fixed_z)\n",
    "                im_grid_real = vutils.make_grid(data[:32], normalize=True)\n",
    "                im_grid_fake = vutils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_data.add_image(\"MNIST\", im_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Generated\", im_grid_fake, global_step=step)\n",
    "            step += 1\n",
    "            # Back to training mode\n",
    "            G.train()\n",
    "            C.train()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
