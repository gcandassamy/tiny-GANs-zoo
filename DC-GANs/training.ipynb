{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About DCGANs...\n",
    "- Published as a conference paper at ICLR 2016 by Alec Radford et al. (Alec Radford later joined OpenAI where he pioneered the works on GPTs!)\n",
    "- The original paper **Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks** can be found at <https://arxiv.org/abs/1511.06434>\n",
    "- One of the first successful applications of CNN architecture in the unsupervised learning paradigm\n",
    "- Propose a set of guidelines on the architectural topology for GANs based on CNNs\n",
    "- The authors show that the generator possess interesting vector arithmetic properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import Discriminator, Generator, initialize_weights\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectural guidelines:\n",
    "- Remove all fully-connected hidden layers\n",
    "- Use batchnorm in both the Generator and the Discriminator (except at the output of G and the input of D)\n",
    "- Use ReLU activation in the Generator (except at the output layer that uses tanh)\n",
    "- Use LeakyReLU activation in the Discriminator with a slope of 0.2\n",
    "\n",
    "Now, look at **model.py** for the implementation of G and D along with the weight initialization routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter configuration (following the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 64\n",
    "IMG_CHANNELS = 3\n",
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 5\n",
    "DISC_FEAT = 64\n",
    "GEN_FEAT = 64\n",
    "BETA1 = 0.5\n",
    "MANUAL_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reproducibility..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(MANUAL_SEED)\n",
    "random.seed(MANUAL_SEED)\n",
    "torch.use_deterministic_algorithms(mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading / preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To see that this architecture could generate \"good-looking\" RGB images, we work with the CelebA dataset <https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>. \n",
    "- To download just the training images, just use this kaggle link: <https://www.kaggle.com/datasets/504743cb487a5aed565ce14238c6343b7d650ffd28c071f03f2fd9b25819e6c9> and extract the files to a folder named **celeb_dataset** in your root (contains ~202K images of celebrities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( (0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "    ]\n",
    ")\n",
    "# For MNIST...\n",
    "# dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms, download=True) # set IMG_CHANNELS = 1\n",
    "\n",
    "# For CelebA\n",
    "dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(dev)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(NOISE_DIM, IMG_CHANNELS, GEN_FEAT).to(dev)\n",
    "G.apply(initialize_weights)\n",
    "D = Discriminator(IMG_CHANNELS, DISC_FEAT).to(dev)\n",
    "D.apply(initialize_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_G = optim.Adam(G.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_z = torch.randn(64, NOISE_DIM, 1, 1).to(dev)\n",
    "writer_data = SummaryWriter(f\"logs/CelebA\")\n",
    "writer_fake = SummaryWriter(f\"logs/Fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the GAN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Generator and Discriminator to training mode...\n",
    "G.train()\n",
    "D.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        D.zero_grad()\n",
    "        real = real.to(dev)\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        # Train with all-real batch\n",
    "        disc_real = D(real).reshape(-1)\n",
    "        loss_D_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        loss_D_real.backward()\n",
    "        D_x = disc_real.mean().item()\n",
    "\n",
    "        # Train with all-fake batch\n",
    "        z = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(dev)\n",
    "        fake = G(z)\n",
    "        disc_fake = D(fake.detach()).reshape(-1)\n",
    "        loss_D_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_D_fake.backward()\n",
    "        D_G_z1 = disc_fake.mean().item()\n",
    "\n",
    "        loss_D = loss_D_real + loss_D_fake \n",
    "        \n",
    "        opt_D.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        G.zero_grad()\n",
    "        output = D(fake).reshape(-1)\n",
    "        loss_G = criterion(output, torch.ones_like(output))\n",
    "        \n",
    "        loss_G.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        opt_G.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\n\n",
    "                Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}, D(x): {D_x}, D(G(z)): {D_G_z1} / {D_G_z2}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = G(fixed_z)\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_data.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
